#  温故而知新

## 从helloworld说起
```c
#include<stdio.h>
int main(){
    printf("hell0,world\n");
    return 0;
}
```
- 程序为啥要编译了才能运行？
- 编译器除了把c代码转为机器码做了什么？如何做？
- 最后编译出来的可执行文件是什么？除了机器码还有什么？ 怎么存放 怎么组织？
- ...
- 期待这本书能够解决问题

## 万变不理其宗


- CPU 存储器，IO设备 ，早期由一根总线连接起来
  - 协调cpu，内存，高速图形设备，设计了高速的北桥芯片
  - 北桥的速度太高，如果低速设备都用北桥设计就会变得复杂，所以又设计了南桥
  <center>
    <img style="border-radius: 1.125em;
    box-shadow: 0 2px 4px 0 rgba(34,36,38,.12),0 2px 10px 0 rgba(34,36,38,.08);"
    src=img/2021-06-17-10-42-24.png
  width=490px>
  </center>
  - 北桥左边是cpu，右边是内存以及下边的pci总线
  

-设备驱动
- 操作系统发展
  - 多道任务处理
  - 多任务处理
- 内存不够怎么办



### SMP与多核
- CPU极限4GHz天花板
- 对称多处理器（SMP），每个cpu在系统中的地位和发挥的作用相同高，相互对称
- 理想的情况是cpu的数量和速度成正比，但是实际情况可能并不是，因为程序并不是都能**分解为若干个完全不相干子问题**
- 多核处理器（Multi-core Processor)


## 站的高望得远
- 系统软件
  - 1. 平台性：操作系统内核，驱动程序，运行库，和许多系统工具
  - 2. 程序开发性：编译器，汇编器，连接器等开发工具和开发库

- 计算机系统体系结构设计要点
  <center>
    <img style="border-radius: 1.125em;
    box-shadow: 0 2px 4px 0 rgba(34,36,38,.12),0 2px 10px 0 rgba(34,36,38,.08);"
    src=img/2021-06-17-10-51-29.png
  width=490px>
  </center>

- 每层之间的通信，需要一个通信协议，我们称之为**接口**
- 应用程序编程接口
- 系统调用接口：实现中都是利用软件中断的方式，Linux中利用0x80号中断作为系统调用接口，windows使用0x2E号


## 操作系统做什么
- 提供抽象接口
- 管理硬件资源

### 不要让cpu打盹
- **多道程序设计：** 当某个程序暂时不用cpu时，就用一个监控程序把另外等待cpu的程序唤醒，虽然非常粗糙（没有优先级）但是大大提高了利用率
- **分时系统：** 每个程序运行一段时间 主动让出cpu，这种协作模式。但是如果一个程序执行一个耗时的计算（如死循环）一直霸占cpu，其他程序没有办法，则整个系统都会死机
- **多任务系统：** 操作系统接管所有硬件资源，并且本身运行在受硬件保护的级别。
  - 所有程序都以进程方式运行在低于操作系统的级别。每个进程运行在独立的地址空间，相互隔离。
  - cpu由操作系统统一调度 ，运行超出一段时间，操作系统会暂停该进程，将cpu分配给其他在等待的程序，**称为抢占式**


### 设备驱动
- unix中硬件设备的访问形式跟普通文件相同
- windows中图形硬件被抽象成了GDI，声音和多媒体被抽象为DirectX

- 文件系统：
  <center>
    <img style="border-radius: 1.125em;
    box-shadow: 0 2px 4px 0 rgba(34,36,38,.12),0 2px 10px 0 rgba(34,36,38,.08);"
    src=img/2021-06-17-11-09-04.png
  width=490px>
  </center>

  - 文件系统保存了文件的存储结构。读取时调用read系统调用，文件系统收到请求后，判断出文件的前4096bytes位于1000号-10007号逻辑扇区，然后发出读逻辑扇区1000开始的8个扇区命令。常见的是利用IO端口寄存器实现，不同硬件分配不同IO端口地址，利用in和out实现读和写
  - 例子p13

## 内存不够怎么办
- 内存分配问题：如何将有限的物理内存分配给多个应用程序
  - 1. 地址空间不隔离（保护物理内存）：
  - 2. 内存使用率低（缓存工具）
  - 3. 程序运行地址不确定（简化内存管理，为每个进程提供了一致的地址空间从而简化存储器管理）：
    - 简化内存分配，链接，加载

### 关于隔离（保护）
- 地址空间可以看作一个很大的数组，每个元素是一个字节
- 物理地址空间是实实在在的物理内存的空间，例如计算机地址总线32根，那么它的地址就是32位，物理空间也就是4GB。如果你的内存只有512M那么实际地址空间0x00000000-0x1FFFFFFF 其他的无效
- 虚拟地址：是虚拟的，人们想出来的地址空间，其实并不存在。虚拟地址到物理地址的映射利用MMU

### 分段
- 最原始的方法：把一段与程序所需要的内存空间大小的虚拟空间映射到某个地址空间。
- 假设A需要10M内存，我们假设有一个0x00000000～0x00A00000 10MB大小的虚拟空间，然后从实际物理内存中分配0x00100000～0x00B00000的空间。两块相同的地址空间一一映射
  <center>
    <img style="border-radius: 1.125em;
    box-shadow: 0 2px 4px 0 rgba(34,36,38,.12),0 2px 10px 0 rgba(34,36,38,.08);"
    src=img/2021-06-18-08-30-04.png
  width=390px>
  </center>
- 分段解决了前面说的第一个问题和第三个问题，即实现了地址空间隔离，简化了内存分配，链接，加载，不再需要重定位。程序只需要关注虚拟地址
- 但是分段没有解决第二个问题：内存使用效率（也就是作为缓存的工具），内存区域的映射还是按照程序为单位，如果内存不足，被换入到换出的到磁盘的都是整个程序，会造成大量的磁盘访问，严重影响速度。因此需要使用分页

### 分页

- 程序局部性原理在分段基础上的改进：程序很多数据在一个时间段内都是不会被用到的，频繁用到的只是一小部分数据。
- 因此需要更小粒度的内存分割和映射，因此提出了分页

- **基本方法：** 将地址空间分为固定大小的页，页大小由操作系统决定，可以是4KB或者4MB，同一时刻只能一种大小。
- 页面大小确定了，虚拟页偏移（VPO）和物理页偏移（PPO）就位数可以确定了，进而确定页号位数（根据页号查找页表中对应的页表条目（PTE）
- 虚拟页（VP），物理页（PP），磁盘页（DP），虚拟页号(VPN),物理页号（PPN）
  <center>
    <img style="border-radius: 1.125em;
    box-shadow: 0 2px 4px 0 rgba(34,36,38,.12),0 2px 10px 0 rgba(34,36,38,.08);"
    src=img/2021-06-18-08-41-16.png
  width=390px>
  </center>
  
- 虚拟页映射到同一个物理页实现内存共享
- 如何映射：MMU
  <center>
    <img style="border-radius: 1.125em;
    box-shadow: 0 2px 4px 0 rgba(34,36,38,.12),0 2px 10px 0 rgba(34,36,38,.08);"
    src=img/2021-06-18-08-43-42.png
  width=490px>
  </center>
  

## 众人拾柴火焰高

### 线程基础
- 线程：轻量级进程，程序执行流的最小单位，含有自己的运行上下文，程序计数器，通用目的寄存器和条件码，堆栈。
- 共享：代码段.text 数据段.data .bss ，堆等，打开的文件，信号
- 一个进程：通常有多个线程
  <center>
    <img style="border-radius: 1.125em;
    box-shadow: 0 2px 4px 0 rgba(34,36,38,.12),0 2px 10px 0 rgba(34,36,38,.08);"
    src=img/2021-06-18-08-54-10.png
  width=390px>
  </center>


- 多线程的优势
  - 某个操作可能陷入长时间等待，等待线程进入睡眠状态，多线程有效利用等待时间
  - 一个线程负责计算，另外一个线程可以负责交互
  - 程序逻辑需要并发
  - 多CPU或者多核计算机本身具备同时执行多个线程能力，单线程程序无法发挥计算机全部计算能力
  - 相比多进程，多线程在数据共享方面更加高效

- 线程的访问权限
  - 栈（对等线程的栈空间）：可看作私有（函数参数）
  - 线程局部存储（TLS）：操作系统为线程提供的单独私有空间
  - 寄存器（包括PC寄存器），寄存器是执行流的私有数据，线程私有

  |  线程私有  |  线程之间共享  |
  |----|----|
  |  局部变量  |  全局变量  |
  |  函数参数  |  堆上的数据  |
  |   TLS    | 函数中的静态变量|
  |          |   程序代码     |
  |          |   打开的文件     |


- 线程调度与优先级
  - 线程的数量小于处理器数量时，线程的并发是真正的并发。单处理器对应多线程情况下，并发是模拟的一种状态
  - 每次执行一小段时间，因此需要线程调度
  - 线程至少有三种状态：运行，就绪，等待（阻塞）
  <center>
    <img style="border-radius: 1.125em;
    box-shadow: 0 2px 4px 0 rgba(34,36,38,.12),0 2px 10px 0 rgba(34,36,38,.08);"
    src=img/2021-06-18-09-10-44.png
  width=390px>
  </center>
  
  - 优先级调度和轮转法
    - 轮转法：让每一个线程执行一小段时间
    - 线程优先级，高优先级的线程更早执行。
    - 用户可以指定优先级
    - 系统根据**IO密集型线程**和**CPU密集型线程**自动调整优先级，IO频繁的程序频繁进入等待状态，占用很少的cpu时间，因此具有高优先级，因此基本都不会用完时间片。而CPU密集型程序会每次占用cpu时间更加长，因此优先级高
    - **饥饿**：优先级低的线程执行之前，总有优先级高的线程。一般是CPU密集型线程优先级高，容易饿死
  - 可抢占和不可抢占
    - 线程用尽时间片后会被强制剥夺继续执行的权利，叫做抢占
    - 不可抢占放弃cpu只有两种情况
      - 线程试图等待某事件，例如IO
      - 主动放弃时间片
  -  Linux的多线程
     - Linux内核中不存在真正的线程概念，Linux将所有执行实体称为任务，每一个任务类似于一个单线程的进程
     - Linux不同任务间可以共享同一个内存空间
  <center>
    <img style="border-radius: 1.125em;
    box-shadow: 0 2px 4px 0 rgba(34,36,38,.12),0 2px 10px 0 rgba(34,36,38,.08);"
    src=img/2021-06-18-09-21-24.png
  width=490px>
  </center>

    - fork函数调用之后：本任务的fork返回新任务（子进程）的pid，而子进程的fork返回0，表示是子进程
    - fork不复制原任务的内存空间，共享**写时复制copy on write**的内存空间。这个空间是只读的，如果要先修改，系统会复制要修改的部分，然后将这一部分单独给某任务使用（可写）拷贝一份整个内存空间。
  <center>
    <img style="border-radius: 1.125em;
    box-shadow: 0 2px 4px 0 rgba(34,36,38,.12),0 2px 10px 0 rgba(34,36,38,.08);"
    src=img/2021-06-18-09-28-20.png
  width=490px>
  </center>
  
    - fork只能产生本任务的镜像，配合exec才能启动新任务。exec用新的执行映像替换当前执行映像。
    - 如果要产生新的线程需要使用clone。clone产生一个新的任务，从指定位置开始，并且（可选的共享）共享进程当前的内存空间和文件等。实际效果就是产生一个线程
  ```c
  int clone(int(*fn)(void*),void* child_stack,int flags,void* arg);
  ```


### 线程安全
- 多线程程序可访问的全局变量和堆数据随时都可能被其他的线程改变。(尽量避免共享全局数据)
- 寄存器在不同线程中的内容是不同的。
- 竞争和原子操作
  - 经典例子i的自增和自减，可以利用原子操作
  - 而复杂的数据结构原子操作无法实现
- 同步和锁
  - **同步**：一个线程访问数据未结束时，其他线程不得对同一个线程进行访问
  - **二元信号量和Mutex**：二元信号量值和mutex只有0和1 **（信号量可以在不同线程获取并释放**，互斥锁Mutex 只能哪个线程获取了互斥量就只能在哪个线程释放这个锁。其他都是类似的
  - **N元信号量**：一个初始值为N的信号量运行N个线程并发访问（可以用mutex和条件变量代替）。尽量少使用信号量
  - **临界区**：是比互斥量更加严格的同步手段。把临界区的锁获取称为进入临界区，反之称为离开临界区。临界区仅限于本进程，而互斥量和信号量在系统任何进程都是可见的，也就是说一个进程创建了mutex或者sem其他进程试图获取锁是合法的
  - 读写锁：对于一段数据多线程同时读是不会出错的。使用信号量，mutex，临界区对于读取频繁的显得非常低效
  <center>
    <img style="border-radius: 1.125em;
    box-shadow: 0 2px 4px 0 rgba(34,36,38,.12),0 2px 10px 0 rgba(34,36,38,.08);"
    src=img/2021-06-18-09-48-54.png
  width=490px>
  </center>
  
  - 条件变量：首先线程等待条件变量（wait），要循环判断（虚假唤醒原因）。线程可以唤醒条件变量。（此时某个或者所有的条件变量的线程都会被唤醒并继续支持）
- 可重入函数与线程安全
  - 1. 多个线程同时执行这个函数
  - 2. 函数自身调用自身
  - 可重入函数表示函数被重入之后不会产生不良效果
    - 不使用任何（局部）静态或者全局的非const变量
    - 不返回任何（局部）静态或者全局的非const变量的指针
    - 仅依赖调用方的参数
    - 不依赖任何单个资源的锁mutex等
    - 不调用任何不可重入的函数
- 过度优化
  - 使用volatile关键字防止过度优化
  - 防止编译器为了提高速度将一个变量缓存到寄存器而不写回
  - 阻止编译器调整操作volatile变量到指令顺序
  - 换序导致出错的例子

  - 单例模式的问题
  ```cpp
  volatile T* pInst = 0;
  T *GetInstance(){
    if(pInst==NULL){
      lock();
      if(pInst == NULL){
        pInst = new T; //包含三步
      }
      unlock();
    }
    return pInst;
  }
  ```
  - new T包含两个步骤：
    - 1.分配内存 
    - 2.调用构造函数
  - pInst = new T;
    - 包含三个步骤：
    - 1.分配内存 
    - 2.在内存的位置调用构造函数，
    - 3.将内存的地址赋值给pInst
  - **2，3顺序可以颠倒**，也就是**可以先给将内存的地址赋值给pInst 然后在再这个位置调用构造对象。因此可能pInst已经不是NULL，但对象还没有构造完毕**。如果这时出现并发调用，第一个if为NULL为false，这时会**直接返回对象未构造完全的pInst地址**，出现意想不到的后果
  - 没有能够阻止换序的方法。只能使用cpu提供的一条指令，称之为barrier。这个指令会阻止cpu将该指令交换到barrier之后。因此temp的顺序不管怎么变，不会在barrier之后，然后再把temp的地址赋值给pInst
    ```cpp
    #define barrier() __asm__ volatile("lwsync");
    volatile T* pInst = 0;
    T *GetInstance(){
      if(pInst==NULL){
        lock();
        if(pInst == NULL){
          T* temp = new T;
          barrier();
          pInst = temp;
        }
        unlock();
      }
      return pInst;
    }
  ```

## 多线程内部情况
三种线程模型
- 一般直接创建的线程都是一对一 例如clone函数（带有ClONE_VM)参数

- 多对一模型

- 多对多模型
